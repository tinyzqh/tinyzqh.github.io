<!DOCTYPE HTML>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <title>Zhiqiang He</title>
    
    <meta name="author" content="Zhiqiang He">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
</head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                    Zhiqiang He (何志强)
                </p>
                <p>
                    I am a Ph.D. student at the <a href="https://www.uec.ac.jp/eng/">University of Electro-Communications</a> (UEC), Tokyo, advised by Prof. <a href="https://liuzhiabc.github.io/">Zhi Liu</a>. 
                    My research focuses on reinforcement learning and its applications across real-world decision-making problems. 
                    Previously, I earned an M.S. from <a href="https://english.neu.edu.cn/">Northeastern
                        University</a> under the supervision of Prof. <a href="http://faculty.neu.edu.cn/wangjiao/zh_CN/zhym/75393/list/index.htm">Jiao Wang</a>.
                    
                  </p>

                  <p>
                    I interned as a Research Engineer at <a href="https://cloud.baidu.com/">Baidu Beijing</a> from June to September 2021 (Received Super Special Offer), followed by a role as a Reinforcement Learning Algorithms Engineer at 
                    <a href="https://www.inspirai.com/">InspirAI</a> from June 2022 to May 2023 (Received Top-Performing Team Prize).

                  </p>
                <p style="text-align:center">
                    <a href="mailto:tinyzqh@gmail.com">Email</a> &nbsp;/&nbsp;
                    <a href="data/CVZhiqiangHe.pdf">CV</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=v6o0Dz8AAAAJ">Google Scholar</a>
                    &nbsp;/&nbsp;
                    <a href="https://github.com/tinyzqh/">Github</a> &nbsp;/&nbsp;
                    <a href="https://www.zhihu.com/people/zhiqianghe">Zhihu</a> &nbsp;/&nbsp;
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/tinyzqh.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 20%;" alt="profile photo" src="images/tinyzqh.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody>
        </table>
          
          
      

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Academic Activities & Awards</h2>
                  <p>
                    Served as a peer reviewer for 
                    <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6488902">IEEE Transactions on Network Science and Engineering</a>; 
                    <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6488907">IEEE Internet of Things Journal</a>; 
                    <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=8782664">IEEE Open Journal of the Computer Society</a>.
                  </p>

                  <p>
                    Awards:
                    <a> UEC SPRING Research Student (2.2 million yen per year, 2025) </a>;
                    <a> Outstanding Graduate (Top 1%, 2019) </a>;
                  </p>
              </td>
            </tr>
          </tbody>
        </table>

    <table
        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
        <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
            <h2>Publication / Preprint</h2>
            </td>

        </tr>
        </tbody>
    </table>

          
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        
        
        <tr onmouseout="marlodoa()" onmouseover="marlodoa_start()">
            <td style="padding: 20px; width: 25%; vertical-align: middle; text-align: center;">
              <div class="image-container">
                <img src='data/marlodoa.jpg' width=130%, style="margin-top:0px;">
              </div>
            </td>
            
            <td style="padding: 40px; width: 75%; vertical-align: middle;">
              <br>
              <a href="https://www.sciencedirect.com/science/article/pii/S2772424725000654">
                <span class="papertitle">Scalable and Reliable Multi-agent Reinforcement Learning for Traffic Assignment</span>
              </a>
              <br>
              <br>
              <a>Leizhen Wang</a>, 
              <a>Peibo Duan</a>, 
              <a>Cheng Lyu</a>, 
              <a>Zewen Wang</a>, 
              <strong>Zhiqiang He</strong>,
              <a>Nan Zheng</a>,
              <a>Zhenliang Ma</a>
              <br>
              <em>Communications in Transportation Research</em>, 2025. (IF=14.5, Q1)
              <br>
              <a href="https://github.com/georgewanglz2019/MARL4TA">Source Code</a> | 
              <a href="paper/marlodoa.pdf" target="_blank">Download PDF</a>

              <p style="font-size: 14px; line-height: 1.6;">
                <em>
                    A scalable multi-agent approach focusing on the action space policy.
                </em>
              </p>
            </td>
        </tr>

        <tr onmouseout="mspp()" onmouseover="mspp_start()">
            <td style="padding: 20px; width: 25%; vertical-align: middle; text-align: center;">
              <div class="image-container">
                <img src='data/mspp.jpg' width=130%, style="margin-top:0px;">
              </div>
            </td>
            
            <td style="padding: 40px; width: 75%; vertical-align: middle;">
              <br>
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S0020025524012751">
                <span class="papertitle">Understanding World Models through Multi-Step Pruning Policy via Reinforcement Learning</span>
              </a>
              <br>
              <br>
              <strong>Zhiqiang He</strong>, 
              <a>Wen Qiu</a>, 
              <a>Wei Zhao</a>, 
              <a>Xun Shao</a>, 
              <a>Zhi Liu</a>
              <br>
              <em>Information Sciences</em>, 2025. (IF=8.1, Q1)
              <br>
              <a href="https://github.com/tinyzqh/MSPP">Source Code</a> | 
              <a href="paper/mspp.pdf" target="_blank">Download PDF</a>

              <p style="font-size: 14px; line-height: 1.6;">
                <em>
                    Parallel Multi-Step Pruning Policies enhance diversity Sampling.  (Analysis of convergence theory for MSPP and its PG Theorem.)
                </em>
              </p>
            </td>
        </tr>

        <tr onmouseout="uavsurvey()" onmouseover="uavsurvey_start()">
            <td style="padding: 20px; width: 25%; vertical-align: middle; text-align: center;">
              <div class="image-container">
                <img src='data/uavsurvey.png' width=130%, style="margin-top:0px;">
              </div>
            </td>
            
            <td style="padding: 40px; width: 75%; vertical-align: middle;">
              <br>
              <a href="https://ieeexplore.ieee.org/document/11047530">
                <span class="papertitle">A Survey on DRL based UAV Communications and Networking: DRL Fundamentals, Applications and Implementations</span>
              </a>
              <br>
              <br>
              <a>Wei Zhao</a>, 
              <a>Shaoxin Cui</a>, 
              <a>Wen Qiu*</a>, 
              <strong>Zhiqiang He*</strong>,
              <a>Zhi Liu</a>, 
              <a>Xiao Zheng</a>, 
              <a>Bomin Mao</a>,
              <a>Nei Kato</a>
              <br>
              <em>IEEE Communications Surveys & Tutorials</em>, 2025. (IF=42.8, Q1),  * Corresponding author
              <br>

              <p style="font-size: 14px; line-height: 1.6;">
                <em>
                    This survey outlines the evolution of fundamental reinforcement learning theory, highlighting how core challenges have driven the development of new methods.
                </em>
              </p>
            </td>
        </tr>


        <tr onmouseout="erlang()" onmouseover="erlang_start()">
            <td style="padding: 20px; width: 25%; vertical-align: middle; text-align: center;">
              <div class="image-container">
                <img src='data/erlang.jpg' width=130%, style="margin-top:0px;">
              </div>
            </td>
            
            <td style="padding: 40px; width: 75%; vertical-align: middle;">
              <br>
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S0031320322001492">
                <span class="papertitle">Erlang planning network: An iterative model-based reinforcement learning with multi-perspective</span>
              </a>
              <br>
              <br>
              <a>Jiao Wang</a>, 
              <a>Lemin Zhang</a>, 
              <strong>Zhiqiang He</strong>, 
              <a>Can Zhu</a>, 
              <a>Zihui Zhao</a>
              <br>
              <em>Pattern Recognition</em>, 2022. (IF=8.5, Q1)
              <br>
              <a href="https://github.com/tinyzqh/MSPP">Source Code</a> | 
              <a href="paper/erlang.pdf" target="_blank">Download PDF</a>

              <p style="font-size: 14px; line-height: 1.6;">
                <em>
                    Bi-level reinforcement learning in Model-Based Reinforcement Learning.
                </em>
              </p>
            </td>
        </tr>

        <tr onmouseout="rlpid()" onmouseover="rlpid_start()">
            <td style="padding: 20px; width: 25%; vertical-align: middle; text-align: center;">
              <div class="image-container">
                <img src='data/rlpid.jpg' width=100%, style="margin-top:0px;">
              </div>
            </td>
            
            <td style="padding: 40px; width: 75%; vertical-align: middle;">
              <br>
              <a href="https://www.mdpi.com/1999-4893/11/5/65">
                <span class="papertitle">Control Strategy of Speed Servo Systems Based on Deep Reinforcement Learning</span>
              </a>
              <br>
              <br>
              <a>Pengzhan Chen</a>, 
              <strong>Zhiqiang He</strong>, 
              <a>Chuanxi Chen</a>, 
              <a>Jiahong Xu</a>
              <br>
              <em>Algorithms</em>, 2018
              <br>
              <a href="https://github.com/tinyzqh/control-of-jump-systems-based-on-reinforcement-learning">Source Code</a> | 
              <a href="https://www.mdpi.com/1999-4893/11/5/65" target="_blank">Download PDF</a> (Cited 58 times)

              <p style="font-size: 14px; line-height: 1.6;">
                <em>
                    First paper applied Reinforcement Learning in Jump Speed Servo System.
                </em>
              </p>

            </td>
        </tr>
      
    </table>

    <div style="width: 150px; height: 150px; margin: auto;">
        <script type="text/javascript" id="clstr_globe" src="https://clustrmaps.com/globe.js?d=sH2_clvSlQO7fMbl5pZuiHGWXPntcF1--uQMFBq_LJg"></script>
    </div>
      

  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
      <td style="padding:0px">
        <br>
        <p style="text-align:center;font-size:small;">
          Thanks <a href="https://jonbarron.info/">Jon Barron </a> for his <a href="https://github.com/jonbarron/jonbarron_website">website template</a>.
        </p>
      </td>
    </tr>
  </tbody></table>

        </td>
      </tr>
    </table>
  </body>
</html>